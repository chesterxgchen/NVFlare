include "default_gpt2.conf"
config {
    batch_size = 12
    block_size = 1024
    bias = False
    real_data = True
    seed = 1337
    device = "cuda" # examples: "cpu", "cuda", "cuda:0", "cuda:1", etc.
    dtype = "bfloat16" # "float32" or "bfloat16" or "float16"
    compile = True # use PyTorch 2.0 to compile the model to be faster
    profile = False # use pytorch profiler, or just simple benchmarking?
}
