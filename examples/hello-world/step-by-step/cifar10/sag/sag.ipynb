{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a554d44-78e0-4078-bf85-bfa2d0551cc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FedAvg Algorithm with SAG (Scatter & Gather) workflow\n",
    "<a id = \"title\"></a>\n",
    "\n",
    "In this example, we will demonstrate the SAG workflow with FedAvg using CIFAR10 dataset. \n",
    "\n",
    "Both Job Lifecycle and training workflow are controlled on the **server side**, we will just use the existing available SAG controller availalbe in NVFLARE. \n",
    "\n",
    "For client side training code, we will leverage new DL to FL **Client API**\n",
    "\n",
    "First, Let's look at the FedAvg Algorithm and SAG Workflow. \n",
    "\n",
    "## FedAvg with SAG\n",
    "<a id = \"sag\"></a>\n",
    "<img src=\"fed_avg.png\" alt=\"FedAvg\" width=50% height=45% /> <img src=\"sag.png\" alt=\"Scatter and Gather\" width=40% height=40% />\n",
    "\n",
    "The Fed Avg aggregation is done on the server side, its weighted on the number of training steps on each client\n",
    " \n",
    "## Convert training code to federated learning training code\n",
    "<a id = \"code\"></a>\n",
    "We will use the original [Training a Classifer](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) example\n",
    "in pytorch as the code base. The cleanup code (remove comments etc.) can be found in [here](../code/dl/train.py)\n",
    "\n",
    "\n",
    "With the NVFLARE DL to FL Client APIs, we need to transform the existing pytorch classifer training code into Federated Classifer training code with few lines of code changes. The already converted code can be found in **[here](../code/fl/train.py)**\n",
    "\n",
    "For detailed discussion how to convert training code into federated learning training code using Client API, you can also checked out the examples [here](https://github.com/NVIDIA/NVFlare/blob/main/examples/hello-world/ml-to-fl/README.md) and code \n",
    "\n",
    "The key changes are the following steps: \n",
    "\n",
    "```\n",
    "    #  import nvflare client API\n",
    "    import nvflare.client as flare\n",
    "\n",
    "    #  initializes NVFlare client API\n",
    "    flare.init()\n",
    "\n",
    "    # gets FLModel from NVFlare\n",
    "    input_model = flare.receive()\n",
    "\n",
    "    # loads model from NVFlare\n",
    "    net.load_state_dict(input_model.params)\n",
    "\n",
    "    # evaluate on received model\n",
    "    accuracy = evaluate(input_model.params)\n",
    "    \n",
    "    # construct trained FL model\n",
    "    output_model = flare.FLModel(\n",
    "        params=net.cpu().state_dict(),\n",
    "        metrics={\"accuracy\": accuracy},\n",
    "        meta={\"NUM_STEPS_CURRENT_ROUND\": steps},\n",
    "    )\n",
    "    \n",
    "    # send model back to NVFlare\n",
    "    flare.send(output_model)\n",
    "```\n",
    "\n",
    "If you are using pytorch-lightning, the changes are much smaller, 1-line import , 1-line change applies to trainer, 1-line global model evaluation. see [cifar10_lightning_examples](https://github.com/NVIDIA/NVFlare/blob/main/examples/hello-world/ml-to-fl/pt/cifar10_lightning_fl.py) \n",
    "# Prepare Data\n",
    "<a id = \"data\"></a>\n",
    "\n",
    "Let's get the data first. Follow the instruction of cifar10, we can download the data with following scripts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e487166-1e47-47db-83cc-f482735b76a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /tmp/nvflare/data/cifar10/cifar-10-python.tar.gz\n",
      "100%|████████████████████████| 170498071/170498071 [00:20<00:00, 8430892.54it/s]\n",
      "Extracting /tmp/nvflare/data/cifar10/cifar-10-python.tar.gz to /tmp/nvflare/data/cifar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_ROOT = \"/tmp/nvflare/data/cifar10\"\n",
    "\n",
    "! python ../data/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667a9be-a911-4485-a3cb-cc2067852545",
   "metadata": {},
   "source": [
    "## Job Folder and Configurations\n",
    "<a id = \"job\"></a>\n",
    "\n",
    "Now we need to setup the configurations for server and clients and constructure Job folder NVFLARE needed to run. We can do this using NVFLARE job CLI. You can study the [Job CLI tutorials](https://github.com/NVIDIA/NVFlare/blob/main/examples/tutorials/job_cli.ipynb) later with all the details. But for now, you can just use the following commands\n",
    "\n",
    "* Find out the available job templates\n",
    "\n",
    "We need to set the job templates directory, so the job cli commands can find the job templates. If have already set NVFLARE_HOME=```<NVFLARE git clone directory> ```then, you can skipt the folllowing step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3d4443-a274-4176-a5ac-b36008178d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare config -jt ../../../../../job_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7608e860-ba67-4c5c-8219-acf5d52860f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following job templates are available: \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "  name                 Description                                                  Controller Type      Client Category     \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "  cyclic_cc_pt         client-controlled cyclic workflow with PyTorch ClientAPI tra client               client_api          \n",
      "  cyclic_pt            server-controlled cyclic workflow with PyTorch ClientAPI tra server               client_api          \n",
      "  psi_csv              private-set intersection for csv data                        server               Executor            \n",
      "  sag_cross_np         scatter & gather and cross-site validation using numpy       server               client executor     \n",
      "  sag_cse_pt           scatter & gather workflow and cross-site evaluation with PyT server               client_api          \n",
      "  sag_gnn              scatter & gather workflow for gnn learning                   server               client_api          \n",
      "  sag_nemo             Scatter and Gather Workflow for NeMo                         server               client_api          \n",
      "  sag_np               scatter & gather workflow using numpy                        server               client_api          \n",
      "  sag_np_cell_pipe     scatter & gather workflow using numpy                        server               client_api          \n",
      "  sag_np_metrics       scatter & gather workflow using numpy                        server               client_api          \n",
      "  sag_pt               scatter & gather workflow using pytorch                      server               client_api          \n",
      "  sag_pt_deploy_map    SAG workflow with pytorch, deploy_map, site-specific configs server               client_api          \n",
      "  sag_pt_executor      scatter & gather workflow and cross-site evaluation with PyT server               Executor            \n",
      "  sag_pt_model_learner scatter & gather workflow and cross-site evaluation with PyT server               ModelLearner        \n",
      "  sag_tf               scatter & gather workflow using TensorFlow                   server               client_api          \n",
      "  sklearn_kmeans       scikit-learn KMeans model                                    server               client_api          \n",
      "  sklearn_linear       scikit-learn linear model                                    server               client_api          \n",
      "  sklearn_svm          scikit-learn SVM model                                       server               client_api          \n",
      "  stats_df             FedStats: tabular data with pandas                           server               stats executor      \n",
      "  stats_image          FedStats: image intensity histogram                          server               stats executor      \n",
      "  swarm_cse_pt         Swarm Learning with Cross-Site Evaluation with PyTorch       client               client_api          \n",
      "  swarm_cse_pt_model_l Swarm Learning with Cross-Site Evaluation with PyTorch Model client               ModelLearner        \n",
      "  vertical_xgb         vertical federated xgboost                                   server               Executor            \n",
      "  xgboost_tree         xgboost horizontal tree-based collaboration model            server               client_api          \n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! nvflare job list_templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c354739-e464-4bca-afbe-eb04baa5751d",
   "metadata": {},
   "source": [
    "* Create job folder and initial configs\n",
    "\n",
    "The template **'sag_pt'** seems to fit our needs: SAG with pytorch, using client API. Lets create a job folder with this template initially without specifying the code location, just see what's needs to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948b39c7-6744-48b4-b73c-47d64c945102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following are the variables you can change in the template\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                                                                                       \n",
      "  job folder: /tmp/nvflare/jobs/cifar10_sag_pt                                                                                           \n",
      "                                                                                                                                       \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  file_name                      var_name                       value                               component                          \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  meta.conf                      app                            ['@ALL']                                                               \n",
      "  meta.conf                      mandatory_clients              []                                                                     \n",
      "  meta.conf                      min_clients                    2                                                                      \n",
      "\n",
      "  config_fed_client.conf         app_config                                                                                            \n",
      "  config_fed_client.conf         app_script                     cifar10.py                                                             \n",
      "  config_fed_client.conf         component_ids                  ['metric_relay']                    ExternalConfigurator               \n",
      "  config_fed_client.conf         config_file_name               client_api_config.json              ExternalConfigurator               \n",
      "  config_fed_client.conf         evaluate_task_name             evaluate                                                               \n",
      "  config_fed_client.conf         event_type                     fed.analytix_log_stats              MetricRelay                        \n",
      "  config_fed_client.conf         file_check_interval            0.1                                 FilePipe                           \n",
      "  config_fed_client.conf         heartbeat_interval             5.0                                 MetricRelay                        \n",
      "  config_fed_client.conf         heartbeat_timeout              30.0                                MetricRelay                        \n",
      "  config_fed_client.conf         last_result_transfer_timeout   5.0                                                                    \n",
      "  config_fed_client.conf         launch_once                    True                                SubprocessLauncher                 \n",
      "  config_fed_client.conf         mode                           PASSIVE                             CellPipe                           \n",
      "  config_fed_client.conf         monitor_interval               0.01                                                                   \n",
      "  config_fed_client.conf         params_exchange_format         pytorch                                                                \n",
      "  config_fed_client.conf         params_transfer_type           DIFF                                                                   \n",
      "  config_fed_client.conf         pipe_channel_name              metric                              MetricRelay                        \n",
      "  config_fed_client.conf         read_interval                  0.001                                                                  \n",
      "  config_fed_client.conf         root_path                      {WORKSPACE}/{JOB_ID}/{SITE_NAME}    FilePipe                           \n",
      "  config_fed_client.conf         root_url                       {ROOT_URL}                          CellPipe                           \n",
      "  config_fed_client.conf         script                         python3 custom/{app_script}  {app_c SubprocessLauncher                 \n",
      "  config_fed_client.conf         secure_mode                    {SECURE_MODE}                       CellPipe                           \n",
      "  config_fed_client.conf         site_name                      {SITE_NAME}                         CellPipe                           \n",
      "  config_fed_client.conf         token                          {JOB_ID}                            CellPipe                           \n",
      "  config_fed_client.conf         train_with_evaluation          True                                                                   \n",
      "  config_fed_client.conf         workers                        4                                                                      \n",
      "  config_fed_client.conf         workspace_dir                  {WORKSPACE}                         CellPipe                           \n",
      "\n",
      "  config_fed_server.conf         allow_empty_global_weights     False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         best_global_model_file_name    best_FL_global_model.pt             PTFileModelPersistor               \n",
      "  config_fed_server.conf         events                         ['fed.analytix_log_stats']          TBAnalyticsReceiver                \n",
      "  config_fed_server.conf         expected_data_kind             WEIGHT_DIFF                         InTimeAccumulateWeightedAggregator \n",
      "  config_fed_server.conf         global_model_file_name         FL_global_model.pt                  PTFileModelPersistor               \n",
      "  config_fed_server.conf         ignore_result_error            False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         key_metric                     accuracy                            IntimeModelSelector                \n",
      "  config_fed_server.conf         min_clients                    2                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         model_class_path               net.Net                                                                \n",
      "  config_fed_server.conf         negate_key_metric              False                               IntimeModelSelector                \n",
      "  config_fed_server.conf         num_rounds                     2                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         persist_every_n_rounds         1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         snapshot_every_n_rounds        1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         start_round                    0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         task_check_period              0.5                                 ScatterAndGather                   \n",
      "  config_fed_server.conf         tb_folder                      tb_events                           TBAnalyticsReceiver                \n",
      "  config_fed_server.conf         train_timeout                  0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         validation_metric_name         initial_metrics                     IntimeModelSelector                \n",
      "  config_fed_server.conf         wait_time_after_min_received   0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         weigh_by_local_iter            False                               IntimeModelSelector                \n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! nvflare job create -j /tmp/nvflare/jobs/cifar10_sag_pt -w sag_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78d674-5d4f-4d2a-8c70-90e538f86727",
   "metadata": {},
   "source": [
    "Lets also looks at the server and client configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b6688e-1072-45b2-b6e1-cd240807d9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  # version of the configuration\n",
      "  format_version = 2\n",
      "\n",
      "  # task data filter: if filters are provided, the filter will filter the data flow out of server to client.\n",
      "  task_data_filters =[]\n",
      "\n",
      "  # task result filter: if filters are provided, the filter will filter the result flow out of client to server.\n",
      "  task_result_filters = []\n",
      "\n",
      "  # This assumes that there will be a \"net.py\" file with class name \"Net\".\n",
      "  # If your model code is not in \"net.py\" and class name is not \"Net\", please modify here\n",
      "  model_class_path = \"net.Net\"\n",
      "\n",
      "  # workflows: Array of workflows the control the Federated Learning workflow lifecycle.\n",
      "  # One can specify multiple workflows. The NVFLARE will run them in the order specified.\n",
      "  workflows = [\n",
      "      {\n",
      "        # 1st workflow\"\n",
      "        id = \"scatter_and_gather\"\n",
      "\n",
      "        # name = ScatterAndGather, path is the class path of the ScatterAndGather controller.\n",
      "        path = \"nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather\"\n",
      "        args {\n",
      "            # argument of the ScatterAndGather class.\n",
      "            # min number of clients required for ScatterAndGather controller to move to the next round\n",
      "            # during the workflow cycle. The controller will wait until the min_clients returned from clients\n",
      "            # before move to the next step.\n",
      "            min_clients = 2\n",
      "\n",
      "            # number of global round of the training.\n",
      "            num_rounds = 2\n",
      "\n",
      "            # starting round is 0-based\n",
      "            start_round = 0\n",
      "\n",
      "            # after received min number of clients' result,\n",
      "            # how much time should we wait further before move to the next step\n",
      "            wait_time_after_min_received = 0\n",
      "\n",
      "            # For ScatterAndGather, the server will aggregate the weights based on the client's result.\n",
      "            # the aggregator component id is named here. One can use the this ID to find the corresponding\n",
      "            # aggregator component listed below\n",
      "            aggregator_id = \"aggregator\"\n",
      "\n",
      "            # The Scatter and Gather controller use an persistor to load the model and save the model.\n",
      "            # The persistent component can be identified by component ID specified here.\n",
      "            persistor_id = \"persistor\"\n",
      "\n",
      "            # Shareable to a communication message, i.e. shared between clients and server.\n",
      "            # Shareable generator is a component that responsible to take the model convert to/from this communication message: Shareable.\n",
      "            # The component can be identified via \"shareable_generator_id\"\n",
      "            shareable_generator_id =  \"shareable_generator\"\n",
      "\n",
      "            # train task name: client side needs to have an executor that handles this task\n",
      "            train_task_name =  \"train\"\n",
      "\n",
      "            # train timeout in second. If zero, meaning no timeout.\n",
      "            train_timeout =  0\n",
      "        }\n",
      "      }\n",
      "  ]\n",
      "\n",
      "  # List of components used in the server side workflow.\n",
      "  components = [\n",
      "    {\n",
      "      # This is the persistence component used in above workflow.\n",
      "      # PTFileModelPersistor is a Pytorch persistor which save/read the model to/from file.\n",
      "\n",
      "      id = \"persistor\"\n",
      "      path = \"nvflare.app_opt.pt.file_model_persistor.PTFileModelPersistor\"\n",
      "\n",
      "      # the persitor class take model class as argument\n",
      "      # This imply that the model is initialized from the server-side.\n",
      "      # The initialized model will be broadcast to all the clients to start the training.\n",
      "      args.model.path = \"{model_class_path}\"\n",
      "    },\n",
      "    {\n",
      "      # This is the generator that convert the model to shareable communication message structure used in workflow\n",
      "      id = \"shareable_generator\"\n",
      "      path = \"nvflare.app_common.shareablegenerators.full_model_shareable_generator.FullModelShareableGenerator\"\n",
      "      args = {}\n",
      "    },\n",
      "    {\n",
      "      # This is the aggregator that perform the weighted average aggregation.\n",
      "      # the aggregation is \"in-time\", so it doesn't wait for client results, but aggregates as soon as it received the data.\n",
      "      id = \"aggregator\"\n",
      "      path = \"nvflare.app_common.aggregators.intime_accumulate_model_aggregator.InTimeAccumulateWeightedAggregator\"\n",
      "      args.expected_data_kind = \"WEIGHT_DIFF\"\n",
      "    },\n",
      "    {\n",
      "      # This component is not directly used in Workflow.\n",
      "      # it select the best model based on the incoming global validation metrics.\n",
      "      id = \"model_selector\"\n",
      "      path =  \"nvflare.app_common.widgets.intime_model_selector.IntimeModelSelector\"\n",
      "      # need to make sure this \"key_metric\" match what server side received\n",
      "      args.key_metric = \"accuracy\"\n",
      "    },\n",
      "    {\n",
      "      id = \"tb_analytics_receiver\"\n",
      "      path = \"nvflare.app_opt.tracking.tb.tb_receiver.TBAnalyticsReceiver\"\n",
      "      args.events = [\"fed.analytix_log_stats\"]\n",
      "    }\n",
      "  ]\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat /tmp/nvflare/jobs/cifar10_sag_pt/app/config/config_fed_server.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174903e1-824d-4a7b-98c4-e190d357a431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  # version of the configuration\n",
      "  format_version = 2\n",
      "\n",
      "  # This is the application script which will be invoked. Client can replace this script with user's own training script.\n",
      "  app_script = \"cifar10.py\"\n",
      "\n",
      "  # Additional arguments needed by the training code. For example, in lightning, these can be --trainer.batch_size=xxx.\n",
      "  app_config = \"\"\n",
      "\n",
      "  # Client Computing Executors.\n",
      "  executors = [\n",
      "    {\n",
      "      # tasks the executors are defined to handle\n",
      "      tasks = [\"train\"]\n",
      "\n",
      "      # This particular executor\n",
      "      executor {\n",
      "\n",
      "        # This is an executor for Client API. The underline data exchange is using Pipe.\n",
      "        path = \"nvflare.app_opt.pt.client_api_launcher_executor.PTClientAPILauncherExecutor\"\n",
      "\n",
      "        args {\n",
      "          # launcher_id is used to locate the Launcher object in \"components\"\n",
      "          launcher_id = \"launcher\"\n",
      "\n",
      "          # pipe_id is used to locate the Pipe object in \"components\"\n",
      "          pipe_id = \"pipe\"\n",
      "\n",
      "          # Timeout in seconds for waiting for a heartbeat from the training script. Defaults to 30 seconds.\n",
      "          # Please refer to the class docstring for all available arguments\n",
      "          heartbeat_timeout = 60\n",
      "\n",
      "          # format of the exchange parameters\n",
      "          params_exchange_format =  \"pytorch\"\n",
      "\n",
      "          # if the transfer_type is FULL, then it will be sent directly\n",
      "          # if the transfer_type is DIFF, then we will calculate the\n",
      "          # difference VS received parameters and send the difference\n",
      "          params_transfer_type = \"DIFF\"\n",
      "\n",
      "          # if train_with_evaluation is true, the executor will expect\n",
      "          # the custom code need to send back both the trained parameters and the evaluation metric\n",
      "          # otherwise only trained parameters are expected\n",
      "          train_with_evaluation = true\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "\n",
      "  # this defined an array of task data filters. If provided, it will control the data from server controller to client executor\n",
      "  task_data_filters =  []\n",
      "\n",
      "  # this defined an array of task result filters. If provided, it will control the result from client executor to server controller\n",
      "  task_result_filters = []\n",
      "\n",
      "  components =  [\n",
      "    {\n",
      "      # component id is \"launcher\"\n",
      "      id = \"launcher\"\n",
      "\n",
      "      # the class path of this component\n",
      "      path = \"nvflare.app_common.launchers.subprocess_launcher.SubprocessLauncher\"\n",
      "\n",
      "      args {\n",
      "        # the launcher will invoke the script\n",
      "        script = \"python3 custom/{app_script}  {app_config} \"\n",
      "        # if launch_once is true, the SubprocessLauncher will launch once for the whole job\n",
      "        # if launch_once is false, the SubprocessLauncher will launch a process for each task it receives from server\n",
      "        launch_once = true\n",
      "      }\n",
      "    }\n",
      "    {\n",
      "      id = \"pipe\"\n",
      "\n",
      "      path = \"nvflare.fuel.utils.pipe.file_pipe.FilePipe\"\n",
      "\n",
      "      args {\n",
      "        mode = \"PASSIVE\"\n",
      "        # root_path: is the directory location of the parameters exchange.\n",
      "        # You can also set it to an absolute path in your system.\n",
      "        root_path = \"{WORKSPACE}/{JOB_ID}/{SITE_NAME}\"\n",
      "      }\n",
      "    }\n",
      "    {\n",
      "      id = \"metrics_pipe\"\n",
      "      path = \"nvflare.fuel.utils.pipe.cell_pipe.CellPipe\"\n",
      "      args {\n",
      "        mode = \"PASSIVE\"\n",
      "        site_name = \"{SITE_NAME}\"\n",
      "        token = \"{JOB_ID}\"\n",
      "        root_url = \"{ROOT_URL}\"\n",
      "        secure_mode = \"{SECURE_MODE}\"\n",
      "        workspace_dir = \"{WORKSPACE}\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      id = \"metric_relay\"\n",
      "      path = \"nvflare.app_common.widgets.metric_relay.MetricRelay\"\n",
      "      args {\n",
      "        pipe_id = \"metrics_pipe\"\n",
      "        event_type = \"fed.analytix_log_stats\"\n",
      "        # how fast should it read from the peer\n",
      "        read_interval = 0.1\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      # we use this component so the client api `flare.init()` can get required information\n",
      "      id = \"config_preparer\"\n",
      "      path = \"nvflare.app_common.widgets.external_configurator.ExternalConfigurator\"\n",
      "      args {\n",
      "        component_ids = [\"metric_relay\"]\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat /tmp/nvflare/jobs/cifar10_sag_pt/app/config/config_fed_client.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb79b5c-f97f-472f-91a5-5a5175fb9759",
   "metadata": {},
   "source": [
    "* Create job folder with all the configs\n",
    "\n",
    "Let's change the num_rounds = 5, script = train.py, min_clients = 2 for meta.conf.  We also like to change the arguments for train.py \n",
    "dataset_path=CIFAR10_ROOT, batch_size=6, num_workers = 2. Here dataset_path is actually not changed, but we just want to show you could change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10603e48-ef80-46fc-9163-e287ce43c803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following are the variables you can change in the template\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                                                                                       \n",
      "  job folder: /tmp/nvflare/jobs/cifar10_sag_pt                                                                                           \n",
      "                                                                                                                                       \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  file_name                      var_name                       value                               component                          \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  meta.conf                      app                            ['@ALL']                                                               \n",
      "  meta.conf                      mandatory_clients              []                                                                     \n",
      "  meta.conf                      min_clients                    2                                                                      \n",
      "\n",
      "  config_fed_client.conf         app_config                     --batch_size 6 --dataset_path /tmp/                                    \n",
      "  config_fed_client.conf         app_script                     train.py                                                               \n",
      "  config_fed_client.conf         component_ids                  ['metric_relay']                    ExternalConfigurator               \n",
      "  config_fed_client.conf         config_file_name               client_api_config.json              ExternalConfigurator               \n",
      "  config_fed_client.conf         evaluate_task_name             evaluate                                                               \n",
      "  config_fed_client.conf         event_type                     fed.analytix_log_stats              MetricRelay                        \n",
      "  config_fed_client.conf         file_check_interval            0.1                                 FilePipe                           \n",
      "  config_fed_client.conf         heartbeat_interval             5.0                                 MetricRelay                        \n",
      "  config_fed_client.conf         heartbeat_timeout              30.0                                MetricRelay                        \n",
      "  config_fed_client.conf         last_result_transfer_timeout   5.0                                                                    \n",
      "  config_fed_client.conf         launch_once                    True                                SubprocessLauncher                 \n",
      "  config_fed_client.conf         mode                           PASSIVE                             CellPipe                           \n",
      "  config_fed_client.conf         monitor_interval               0.01                                                                   \n",
      "  config_fed_client.conf         params_exchange_format         pytorch                                                                \n",
      "  config_fed_client.conf         params_transfer_type           DIFF                                                                   \n",
      "  config_fed_client.conf         pipe_channel_name              metric                              MetricRelay                        \n",
      "  config_fed_client.conf         read_interval                  0.001                                                                  \n",
      "  config_fed_client.conf         root_path                      {WORKSPACE}/{JOB_ID}/{SITE_NAME}    FilePipe                           \n",
      "  config_fed_client.conf         root_url                       {ROOT_URL}                          CellPipe                           \n",
      "  config_fed_client.conf         script                         python3 custom/{app_script}  {app_c SubprocessLauncher                 \n",
      "  config_fed_client.conf         secure_mode                    {SECURE_MODE}                       CellPipe                           \n",
      "  config_fed_client.conf         site_name                      {SITE_NAME}                         CellPipe                           \n",
      "  config_fed_client.conf         token                          {JOB_ID}                            CellPipe                           \n",
      "  config_fed_client.conf         train_with_evaluation          True                                                                   \n",
      "  config_fed_client.conf         workers                        4                                                                      \n",
      "  config_fed_client.conf         workspace_dir                  {WORKSPACE}                         CellPipe                           \n",
      "\n",
      "  config_fed_server.conf         allow_empty_global_weights     False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         best_global_model_file_name    best_FL_global_model.pt             PTFileModelPersistor               \n",
      "  config_fed_server.conf         events                         ['fed.analytix_log_stats']          TBAnalyticsReceiver                \n",
      "  config_fed_server.conf         expected_data_kind             WEIGHT_DIFF                         InTimeAccumulateWeightedAggregator \n",
      "  config_fed_server.conf         global_model_file_name         FL_global_model.pt                  PTFileModelPersistor               \n",
      "  config_fed_server.conf         ignore_result_error            False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         key_metric                     accuracy                            IntimeModelSelector                \n",
      "  config_fed_server.conf         min_clients                    2                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         model_class_path               net.Net                                                                \n",
      "  config_fed_server.conf         negate_key_metric              False                               IntimeModelSelector                \n",
      "  config_fed_server.conf         num_rounds                     5                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         persist_every_n_rounds         1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         snapshot_every_n_rounds        1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         start_round                    0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         task_check_period              0.5                                 ScatterAndGather                   \n",
      "  config_fed_server.conf         tb_folder                      tb_events                           TBAnalyticsReceiver                \n",
      "  config_fed_server.conf         train_timeout                  0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         validation_metric_name         initial_metrics                     IntimeModelSelector                \n",
      "  config_fed_server.conf         wait_time_after_min_received   0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         weigh_by_local_iter            False                               IntimeModelSelector                \n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! nvflare job create -j /tmp/nvflare/jobs/cifar10_sag_pt -w sag_pt \\\n",
    "-f meta.conf min_clients=2 \\\n",
    "-f config_fed_client.conf app_script=train.py app_config=\"--batch_size 6 --dataset_path {CIFAR10_ROOT} --num_workers 2\" \\\n",
    "-f config_fed_server.conf num_rounds=5 \\\n",
    "-sd ../code/fl \\\n",
    "-force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208467c-8cf7-4446-963e-af92f79bfad5",
   "metadata": {},
   "source": [
    "OK, we are ready to run the job, let's look at the job folder, use \"ls -al\" if you don't have \"tree\" installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf68fbb-eefc-4268-b341-2558dfe35c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! tree /tmp/nvflare/jobs/cifar10_sag_pt  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05147756-57b3-4976-bddf-794a1cd0fd4d",
   "metadata": {},
   "source": [
    "## Run Job\n",
    "We can use simulator to run the job directly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd4d00-810f-416c-a2e1-e469a9697e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare simulator /tmp/nvflare/jobs/cifar10_sag_pt  -w /tmp/nvflare/jobs/cifar10_sag_pt_workspace -t 2 -n 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b055bde7-432d-4e6b-9163-b5ab7ede7b73",
   "metadata": {},
   "source": [
    "The job should be running in the simulator mode. We are done with the training. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
